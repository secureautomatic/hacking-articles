{"id":"https://thehackernews.com/2024/11/critical-flaws-in-ollama-ai-framework.html","title":"Critical Flaws in Ollama AI Framework Could Enable DoS, Model Theft, and Poisoning","link":"https://thehackernews.com/2024/11/critical-flaws-in-ollama-ai-framework.html","published":1730729280000,"description":"Cybersecurity researchers have disclosed six security flaws in the Ollama artificial intelligence (AI) framework that could be exploited by a malicious actor to perform various actions, including denial-of-service, model poisoning, and model theft. \"Collectively, the vulnerabilities could allow an attacker to carry out a wide-range of malicious actions with a single HTTP request, including","enclosure":{"url":"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi8FRy4wQ1bWDdcWY23WuBNE0AHcxnPTCeidTtUXfmDHmK62fFOm0PZdQiNxGlhxh5B3UqM_pSbG7BegSyTEoTT57gjjObtr8YjBZtw-4XMiypdlmlg7wnzTKUhPNqLdWti6KcshPDnV8i2rkF78JJTG1kFu7tZFoOTH_n3p76-nBw8Da1M0LlFUVr8eee2/s1600/ai.png","type":"image/jpeg","length":"12216320"},"pubDate":"Mon, 04 Nov 2024 19:38:00 +0530"}