{"id":"https://thehackernews.com/2025/08/researchers-uncover-gpt-5-jailbreak-and.html","title":"Researchers Uncover GPT-5 Jailbreak and Zero-Click AI Agent Attacks Exposing Cloud and IoT Systems","link":"https://thehackernews.com/2025/08/researchers-uncover-gpt-5-jailbreak-and.html","published":1754751960000,"description":"Cybersecurity researchers have uncovered a jailbreak technique to bypass ethical guardrails erected by OpenAI in its latest large language model (LLM) GPT-5 and produce illicit instructions. Generative artificial intelligence (AI) security platform NeuralTrust said it combined a known technique called Echo Chamber with narrative-driven steering to trick the model into producing undesirable","enclosure":{"url":"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi_Uhyphenhyphenxqmx-YFtu0edO1LJAex71LSDENFG7qvAc-eGKpbcu-XkXZ0koaI2huQsBLszbXznZ4y3eGtPAJr8HLap02Wv2qL6ybtVu3FkM7hp7MV7I9rNiHEq2QdW9hLahK18pPOSB8otZ0u4UiqdUy8bfAmYqtE7o4yFoidHht-LxqZAtIIVFcsmOYAzgK0HF/s1600/chatgpt-5-jailbreak.jpg","type":"image/jpeg","length":"12216320"},"pubDate":"Sat, 09 Aug 2025 20:36:00 +0530"}